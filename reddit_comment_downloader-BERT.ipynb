{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in d:\\anaconda1\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: praw==7.5.0 in d:\\anaconda1\\lib\\site-packages (7.5.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in d:\\anaconda1\\lib\\site-packages (from praw==7.5.0) (0.18.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in d:\\anaconda1\\lib\\site-packages (from praw==7.5.0) (2.3.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in d:\\anaconda1\\lib\\site-packages (from praw==7.5.0) (1.3.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in d:\\anaconda1\\lib\\site-packages (from prawcore<3,>=2.1->praw==7.5.0) (2.18.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\anaconda1\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw==7.5.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in d:\\anaconda1\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw==7.5.0) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in d:\\anaconda1\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw==7.5.0) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda1\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw==7.5.0) (2021.5.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install pathlib\n",
    "!pip install praw==7.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import pandas as pd\n",
    "#sophie\n",
    "filepath = Path(\"C:/Users/Charlie Lu\\Desktop/Sentiment Analysis/BERT-Sentiment-Analysis-Reddit-API/MadeMeSmile.csv\")  #Location of output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_posts = 25 #number of posts parsed from \"hot\" catagory *note: some will be filtered out, expect about 20% returns*\n",
    "num_comments = 10 #number of comments desired per post\n",
    "get_comments = 10 #number of comments you want to download\n",
    "\n",
    "client_id = \"gxhn82P_P7Qcdrqfn9WOJQ\" #\"Script\" Public id from https://www.reddit.com/prefs/apps\n",
    "client_secret = \"ulaRx22uSoS9yQxN29s8WqhBYiLb5w\" #\"Script\" Private id from https://www.reddit.com/prefs/apps\n",
    "username = \"DataCollector123\" #reddit account username\n",
    "password = \"NotaRobot\" #reddit account password\n",
    "user_agent = \"prawdatacollector\"\n",
    "\n",
    "subreddit = \"MadeMeSmile\" #name of subreddit\n",
    "reddit = praw.Reddit(client_id = client_id,\n",
    "                     client_secret = client_secret,\n",
    "                     username = username,\n",
    "                     password = password,\n",
    "                     user_agent = user_agent)\n",
    "\n",
    "subreddit = reddit.subreddit(subreddit) \n",
    "#set parameters for post listing\n",
    "subreddit_posts = subreddit.top(time_filter=\"all\", limit=num_posts)\n",
    "\n",
    "data = []\n",
    "post_num = 1\n",
    "for post in subreddit_posts:\n",
    "    comments = post.comments.list()\n",
    "    #check comment length, and post type i.redd.it = image post\n",
    "    if len(comments) >= num_comments:\n",
    "        print(post_num)\n",
    "        post_num+=1\n",
    "        #temp.append(post.title)\n",
    "        #temp.append(post.url)\n",
    "        #print(post.title)\n",
    "        j = 0\n",
    "        while j != get_comments:\n",
    "            #print(comments[j].body)\n",
    "            try:\n",
    "                data.append(post.comments[j].body)\n",
    "                j += 1\n",
    "            except:\n",
    "                data.append(\"NA\")\n",
    "                j += 1\n",
    "    else:\n",
    "        post_num += 1\n",
    "\n",
    "df = pd.DataFrame(data) #, columns=['Title', 'Image_URL', 'Comment_1','Comment_2','Comment_3','Comment_4','Comment_5','Comment_6','Comment_7','Comment_8','Comment_9','Comment_10'])\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df.to_csv(filepath)  \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
