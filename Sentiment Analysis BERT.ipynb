{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f8f3b4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#windows machine\n",
    "#!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91a25f15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install transformers pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f03c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31061e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "540b23a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 10372, 10127, 10103, 11146, 69217,   151, 10574, 15765, 10407,\n",
      "           119,   102]])\n"
     ]
    }
   ],
   "source": [
    "#Test the model functionality\n",
    "\n",
    "#tokenize the sentence\n",
    "tokens = tokenizer.encode('This is the best streak I have ever had.', return_tensors='pt')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04bbde29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8257, -2.1205, -1.2404,  0.6951,  3.8157]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#results on a scale of 1-5 with probability displayed respectively\n",
    "result = model(tokens)\n",
    "print(result.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5317fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Result of sentiment analysis on a scale of 1-5, 1 being extremely negative, 5 being extremely positive\n",
    "int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcfa29a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20 years?! I feel old now</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good for Scrat but sad for me.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why do I feel sad?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>It_ ok, you can rest now</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>So long folks!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1                         Column2  Rating\n",
       "0        0       20 years?! I feel old now       1\n",
       "1        1  Good for Scrat but sad for me.       1\n",
       "2        2              Why do I feel sad?       1\n",
       "3        3        It_ ok, you can rest now       2\n",
       "4        4                  So long folks!       3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets grab some DATA!!!\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"MadeMeSmile_jk.csv\",encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b64cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = data['Column2']\n",
    "rating = data['Rating']\n",
    "comments = comments[:950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1d0313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store erroneous evaluations for analysis\n",
    "errors = []\n",
    "\n",
    "\n",
    "#generalize the scale of 1-5 by making 1-2 = 1 and 4-5 = 3\n",
    "for i in range(1,len(comments)):\n",
    "    comment = comments[i]\n",
    "    tokens = tokenizer.encode(comment, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    pred = int(torch.argmax(result.logits))+1\n",
    "    if pred in [1,2]:\n",
    "        pred = 1\n",
    "    elif pred in [4,5]:\n",
    "        pred = 3\n",
    "    elif pred in [3]:\n",
    "        pred = 2\n",
    "    if pred != int(rating[i]):\n",
    "        errors.append((i+1,comments[i],pred,int(rating[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf23bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n",
      "0.7463157894736843\n"
     ]
    }
   ],
   "source": [
    "#check accuracy of model on manually labeled data\n",
    "acc = 1-len(errors)/len(comments)\n",
    "print(len(errors))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80cfb0c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Good for Scrat but sad for me.', 2, 1),\n",
       " (6,\n",
       "  'Looked forward to that little fucker before every movie*pours one for the homie.',\n",
       "  3,\n",
       "  1),\n",
       " (8, 'I didn_ realize how complete this would make me feel', 2, 3),\n",
       " (14,\n",
       "  \"I love his facial expression in the end though, it's like he's saying: ' Look at this, Putin, you fucking bitch'\",\n",
       "  2,\n",
       "  3),\n",
       " (34,\n",
       "  'I surprised to see so many uncovered faces, not for covid reasons but for safety',\n",
       "  3,\n",
       "  1),\n",
       " (40, 'Congratulations! Now move that fridge to the left ??', 1, 3),\n",
       " (42,\n",
       "  'If you don mind me asking, how did you pull this off? Did you land a job somewhere and how did you manage those responsibilities while being homeless?\\n\\nSorry for prying but I genuinely pumped for you and curious as to how you managed to achieve something that seems impossible for so many. Cheers to you my friend!',\n",
       "  1,\n",
       "  3),\n",
       " (44, 'You dropped this ??', 1, 2),\n",
       " (46, 'Noice! Congrats!', 1, 3),\n",
       " (48, 'Not feeling creepy AND fresh tamales!? Yooooooo!!', 1, 3),\n",
       " (51, 'Hey, that_ me! Lol.', 1, 3),\n",
       " (54,\n",
       "  'I use to play halo with the neighbor kids every Friday night. I really miss those times and kids. I remember one time the youngest kid (10) asked me \"how did you get so good\" I looked at him and told him, I\\'ve been playing this longer than you have been alive.',\n",
       "  3,\n",
       "  2),\n",
       " (55,\n",
       "  'The reason I have a kid right now is because a random kid walked up to me on a cruise ship and wanted to play ping pong. I was playing with my wife, and this little boy, maybe about 6, wanted to play.\\n\\nSo, I spent like an hour playing ping pong with this little dude, his parents nowhere in sight the whole time. \\n\\nMy wife, after seeing me playing with a little kid, decided that we needed to have one of our own, *immediately*.',\n",
       "  1,\n",
       "  2),\n",
       " (71,\n",
       "  \"Damn. This tells a story. In 2016, she looks so empty because he isn't with her. You can really tell that they loved each other.\",\n",
       "  1,\n",
       "  3),\n",
       " (77,\n",
       "  'Really felt for the dog when it saw the guy pick up the bat, and it just stopped, not sure what to do.\\n\\nGlad the player realised and threw the bat though. The universe is back in balance ??',\n",
       "  1,\n",
       "  2),\n",
       " (78, 'Dogs with jobs', 3, 2),\n",
       " (91, 'I miss my dad', 2, 1),\n",
       " (95,\n",
       "  \"The way the old people remember dates is incredible .\\n\\nI'm 25 and i can barely remember birthdays.\\n\\nI've always got a hard time to remember a date of anything.\",\n",
       "  3,\n",
       "  1),\n",
       " (96,\n",
       "  'I thought she was going to grab a vase with her moms ashes in it',\n",
       "  1,\n",
       "  2),\n",
       " (100, 'She basically has to say yes to marriage at that point right?', 1, 2)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#observe errors in detail\n",
    "errors[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9ef36",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
