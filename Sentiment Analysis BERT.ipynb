{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f8f3b4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#windows machine\n",
    "#!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91a25f15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install transformers pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8f03c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31061e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "540b23a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 10372, 10127, 10103, 11146, 69217,   151, 10574, 15765, 10407,\n",
      "           119,   102]])\n"
     ]
    }
   ],
   "source": [
    "#Test the model functionality\n",
    "\n",
    "#tokenize the sentence\n",
    "tokens = tokenizer.encode('This is the best streak I have ever had.', return_tensors='pt')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04bbde29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8257, -2.1205, -1.2404,  0.6951,  3.8157]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#results on a scale of 1-5 with probability displayed respectively\n",
    "result = model(tokens)\n",
    "print(result.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5317fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Result of sentiment analysis on a scale of 1-5, 1 being extremely negative, 5 being extremely positive\n",
    "int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcfa29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets grab some DATA!!!\n",
    "\n",
    "#!pip install pathlib\n",
    "#!pip install praw==7.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import pandas as pd\n",
    "filepath = Path(\"C:/Users/Charlie Lu\\Desktop/Sentiment Analysis/RedditAPI/test.csv\")  #Location of output CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
