{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f8f3b4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#windows machine\n",
    "#!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91a25f15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install transformers pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8f03c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31061e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "540b23a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 10372, 10127, 10103, 11146, 69217,   151, 10574, 15765, 10407,\n",
      "           119,   102]])\n"
     ]
    }
   ],
   "source": [
    "#Test the model functionality\n",
    "\n",
    "#tokenize the sentence\n",
    "tokens = tokenizer.encode('This is the best streak I have ever had.', return_tensors='pt')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04bbde29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8257, -2.1205, -1.2404,  0.6951,  3.8157]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#results on a scale of 1-5 with probability displayed respectively\n",
    "result = model(tokens)\n",
    "print(result.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5317fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Result of sentiment analysis on a scale of 1-5, 1 being extremely negative, 5 being extremely positive\n",
    "int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bcfa29a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20 years?! I feel old now</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Good for Scrat but sad for me.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Why do I feel sad?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Its ok, you can rest now</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1                         Column2  Rating\n",
       "0      NaN                               0     NaN\n",
       "1      0.0       20 years?! I feel old now     1.0\n",
       "2      1.0  Good for Scrat but sad for me.     2.0\n",
       "3      2.0              Why do I feel sad?     1.0\n",
       "4      3.0      Its ok, you can rest now\n",
       "     2.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets grab some DATA!!!\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"MadeMeSmile.csv\",encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5b64cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = data['Column2']\n",
    "rating = data['Rating']\n",
    "comments = comments[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f1d0313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "for i in range(1,len(comments)):\n",
    "    comment = comments[i]\n",
    "    tokens = tokenizer.encode(comment, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    pred = int(torch.argmax(result.logits))+1\n",
    "    if pred in [1,2]:\n",
    "        pred = 1\n",
    "    elif pred in [4,5]:\n",
    "        pred = 3\n",
    "    elif pred in [3]:\n",
    "        pred = 2\n",
    "    if pred != int(rating[i]):\n",
    "        errors.append((i+1,comments[i],pred,int(rating[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cf23bae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666666"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 1-len(errors)/len(comments)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80cfb0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 'So long folks!', 3, 2),\n",
       " (7,\n",
       "  'Looked forward to that little fucker before every movie\\x85*pours one for the homie.',\n",
       "  3,\n",
       "  1),\n",
       " (9, 'I didn\\x92t realize how complete this would make me feel', 2, 3),\n",
       " (16,\n",
       "  \"I love his facial expression in the end though, it's like he's saying: ' Look at this, Putin, you fucking bitch'\",\n",
       "  2,\n",
       "  3),\n",
       " (24, 'I guess IT never told them', 1, 2),\n",
       " (27,\n",
       "  'lmao at the co-anchor pretend-falling to the ground @ 0.19, I did not expect that',\n",
       "  1,\n",
       "  3),\n",
       " (28,\n",
       "  \"LOL of course it's Dutra. We had him at a local station for a while before he went to Denver and then Chicago\",\n",
       "  2,\n",
       "  3)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60467b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
